{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\mithun\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "from nltk.corpus import brown\n",
    "brown.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\mithun\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'The', 'Tragedie', 'of', 'Hamlet', 'by', ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamlet=nltk.corpus.gutenberg.words('shakespeare-hamlet.txt')\n",
    "hamlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ The Tragedie of Hamlet by William Shakespeare 1599 ] Actus Primus . Scoena Prima . Enter Barnardo and Francisco two Centinels . Barnardo . Who ' s there ? Fran . Nay answer me : Stand & vnfold your selfe Bar . Long liue the King Fran . Barnardo ? Bar . He Fran . You come most carefully vpon your houre Bar . ' Tis now strook twelue , get thee to bed Francisco Fran . For this releefe much thankes : ' Tis bitter cold , And I am sicke at heart Barn . Haue you had "
     ]
    }
   ],
   "source": [
    "for word in hamlet[:100]:\n",
    "    print(word, sep=' ',end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NLP = \"\"\"NLP combines computational linguistics—rule-based modeling of human language—with statistical, machine learning, and deep learning models. Together, these technologies enable computers to process human language in the form of text or voice data and to ‘understand’ its full meaning, complete with the speaker or writer’s intent and sentiment.\n",
    "\n",
    "NLP drives computer programs that translate text from one language to another, respond to spoken commands, and summarize large volumes of text rapidly—even in real time. There’s a good chance you’ve interacted with NLP in the form of voice-operated GPS systems, digital assistants, speech-to-text dictation software, customer service chatbots, and other consumer conveniences. But NLP also plays a growing role in enterprise solutions that help streamline business operations, increase employee productivity, and simplify mission-critical business processes.\"\"\"\n",
    "type(NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLP',\n",
       " 'combines',\n",
       " 'computational',\n",
       " 'linguistics—rule-based',\n",
       " 'modeling',\n",
       " 'of',\n",
       " 'human',\n",
       " 'language—with',\n",
       " 'statistical',\n",
       " ',',\n",
       " 'machine',\n",
       " 'learning',\n",
       " ',',\n",
       " 'and',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'models',\n",
       " '.',\n",
       " 'Together',\n",
       " ',',\n",
       " 'these',\n",
       " 'technologies',\n",
       " 'enable',\n",
       " 'computers',\n",
       " 'to',\n",
       " 'process',\n",
       " 'human',\n",
       " 'language',\n",
       " 'in',\n",
       " 'the',\n",
       " 'form',\n",
       " 'of',\n",
       " 'text',\n",
       " 'or',\n",
       " 'voice',\n",
       " 'data',\n",
       " 'and',\n",
       " 'to',\n",
       " '‘',\n",
       " 'understand',\n",
       " '’',\n",
       " 'its',\n",
       " 'full',\n",
       " 'meaning',\n",
       " ',',\n",
       " 'complete',\n",
       " 'with',\n",
       " 'the',\n",
       " 'speaker',\n",
       " 'or',\n",
       " 'writer',\n",
       " '’',\n",
       " 's',\n",
       " 'intent',\n",
       " 'and',\n",
       " 'sentiment',\n",
       " '.',\n",
       " 'NLP',\n",
       " 'drives',\n",
       " 'computer',\n",
       " 'programs',\n",
       " 'that',\n",
       " 'translate',\n",
       " 'text',\n",
       " 'from',\n",
       " 'one',\n",
       " 'language',\n",
       " 'to',\n",
       " 'another',\n",
       " ',',\n",
       " 'respond',\n",
       " 'to',\n",
       " 'spoken',\n",
       " 'commands',\n",
       " ',',\n",
       " 'and',\n",
       " 'summarize',\n",
       " 'large',\n",
       " 'volumes',\n",
       " 'of',\n",
       " 'text',\n",
       " 'rapidly—even',\n",
       " 'in',\n",
       " 'real',\n",
       " 'time',\n",
       " '.',\n",
       " 'There',\n",
       " '’',\n",
       " 's',\n",
       " 'a',\n",
       " 'good',\n",
       " 'chance',\n",
       " 'you',\n",
       " '’',\n",
       " 've',\n",
       " 'interacted',\n",
       " 'with',\n",
       " 'NLP',\n",
       " 'in',\n",
       " 'the',\n",
       " 'form',\n",
       " 'of',\n",
       " 'voice-operated',\n",
       " 'GPS',\n",
       " 'systems',\n",
       " ',',\n",
       " 'digital',\n",
       " 'assistants',\n",
       " ',',\n",
       " 'speech-to-text',\n",
       " 'dictation',\n",
       " 'software',\n",
       " ',',\n",
       " 'customer',\n",
       " 'service',\n",
       " 'chatbots',\n",
       " ',',\n",
       " 'and',\n",
       " 'other',\n",
       " 'consumer',\n",
       " 'conveniences',\n",
       " '.',\n",
       " 'But',\n",
       " 'NLP',\n",
       " 'also',\n",
       " 'plays',\n",
       " 'a',\n",
       " 'growing',\n",
       " 'role',\n",
       " 'in',\n",
       " 'enterprise',\n",
       " 'solutions',\n",
       " 'that',\n",
       " 'help',\n",
       " 'streamline',\n",
       " 'business',\n",
       " 'operations',\n",
       " ',',\n",
       " 'increase',\n",
       " 'employee',\n",
       " 'productivity',\n",
       " ',',\n",
       " 'and',\n",
       " 'simplify',\n",
       " 'mission-critical',\n",
       " 'business',\n",
       " 'processes',\n",
       " '.']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "NLP_Tokenized = word_tokenize(NLP)\n",
    "NLP_Tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(NLP_Tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 12, 'and': 6, '.': 5, 'nlp': 4, 'of': 4, 'to': 4, 'in': 4, '’': 4, 'the': 3, 'text': 3, ...})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in NLP_Tokenized:\n",
    "    fdist[word.lower()]+=1\n",
    "fdist\n",
    "# frequency of word\n",
    "# shows how many times words or characters repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frequency of particular word\n",
    "fdist['language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total distinct tokens available\n",
    "len(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 12), ('and', 6), ('.', 5), ('nlp', 4), ('of', 4)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top most 5 common words\n",
    "fdist_top5 = fdist.most_common(5)\n",
    "fdist_top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gives number of new lines\n",
    "from nltk.tokenize import blankline_tokenize\n",
    "NLP_blank=blankline_tokenize(NLP)\n",
    "len(NLP_blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NLP drives computer programs that translate text from one language to another, respond to spoken commands, and summarize large volumes of text rapidly—even in real time. There’s a good chance you’ve interacted with NLP in the form of voice-operated GPS systems, digital assistants, speech-to-text dictation software, customer service chatbots, and other consumer conveniences. But NLP also plays a growing role in enterprise solutions that help streamline business operations, increase employee productivity, and simplify mission-critical business processes.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NLP_blank[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bigrams trigrams ngrams\n",
    "from nltk.util import bigrams, trigrams, ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'this',\n",
       " 'paper',\n",
       " 'we',\n",
       " 'present',\n",
       " 'an',\n",
       " 'approach',\n",
       " 'to',\n",
       " 'the',\n",
       " 'part-of-speech',\n",
       " 'tagging',\n",
       " 'problem',\n",
       " 'based',\n",
       " 'on',\n",
       " 'particle',\n",
       " 'swarm',\n",
       " 'optimization',\n",
       " '.',\n",
       " 'The',\n",
       " 'part-of-speech',\n",
       " 'tagging',\n",
       " 'is',\n",
       " 'a',\n",
       " 'key',\n",
       " 'input',\n",
       " 'feature',\n",
       " 'for',\n",
       " 'several',\n",
       " 'other',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'tasks',\n",
       " ',',\n",
       " 'like',\n",
       " 'phrase',\n",
       " 'chunking',\n",
       " 'and',\n",
       " 'named',\n",
       " 'entity',\n",
       " 'recognition',\n",
       " '.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"In this paper we present an approach to the part-of-speech tagging problem based on particle swarm optimization. The part-of-speech tagging is a key input feature for several other natural language processing tasks, like phrase chunking and named entity recognition.\"\n",
    "sentence_tokenize = nltk.word_tokenize(sentence)\n",
    "sentence_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('In', 'this'),\n",
       " ('this', 'paper'),\n",
       " ('paper', 'we'),\n",
       " ('we', 'present'),\n",
       " ('present', 'an'),\n",
       " ('an', 'approach'),\n",
       " ('approach', 'to'),\n",
       " ('to', 'the'),\n",
       " ('the', 'part-of-speech'),\n",
       " ('part-of-speech', 'tagging'),\n",
       " ('tagging', 'problem'),\n",
       " ('problem', 'based'),\n",
       " ('based', 'on'),\n",
       " ('on', 'particle'),\n",
       " ('particle', 'swarm'),\n",
       " ('swarm', 'optimization'),\n",
       " ('optimization', '.'),\n",
       " ('.', 'The'),\n",
       " ('The', 'part-of-speech'),\n",
       " ('part-of-speech', 'tagging'),\n",
       " ('tagging', 'is'),\n",
       " ('is', 'a'),\n",
       " ('a', 'key'),\n",
       " ('key', 'input'),\n",
       " ('input', 'feature'),\n",
       " ('feature', 'for'),\n",
       " ('for', 'several'),\n",
       " ('several', 'other'),\n",
       " ('other', 'natural'),\n",
       " ('natural', 'language'),\n",
       " ('language', 'processing'),\n",
       " ('processing', 'tasks'),\n",
       " ('tasks', ','),\n",
       " (',', 'like'),\n",
       " ('like', 'phrase'),\n",
       " ('phrase', 'chunking'),\n",
       " ('chunking', 'and'),\n",
       " ('and', 'named'),\n",
       " ('named', 'entity'),\n",
       " ('entity', 'recognition'),\n",
       " ('recognition', '.')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_bigrams = list(nltk.bigrams(sentence_tokenize))\n",
    "sentence_trigrams = list(nltk.trigrams(sentence_tokenize))\n",
    "sentence_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('In', 'this', 'paper'),\n",
       " ('this', 'paper', 'we'),\n",
       " ('paper', 'we', 'present'),\n",
       " ('we', 'present', 'an'),\n",
       " ('present', 'an', 'approach'),\n",
       " ('an', 'approach', 'to'),\n",
       " ('approach', 'to', 'the'),\n",
       " ('to', 'the', 'part-of-speech'),\n",
       " ('the', 'part-of-speech', 'tagging'),\n",
       " ('part-of-speech', 'tagging', 'problem'),\n",
       " ('tagging', 'problem', 'based'),\n",
       " ('problem', 'based', 'on'),\n",
       " ('based', 'on', 'particle'),\n",
       " ('on', 'particle', 'swarm'),\n",
       " ('particle', 'swarm', 'optimization'),\n",
       " ('swarm', 'optimization', '.'),\n",
       " ('optimization', '.', 'The'),\n",
       " ('.', 'The', 'part-of-speech'),\n",
       " ('The', 'part-of-speech', 'tagging'),\n",
       " ('part-of-speech', 'tagging', 'is'),\n",
       " ('tagging', 'is', 'a'),\n",
       " ('is', 'a', 'key'),\n",
       " ('a', 'key', 'input'),\n",
       " ('key', 'input', 'feature'),\n",
       " ('input', 'feature', 'for'),\n",
       " ('feature', 'for', 'several'),\n",
       " ('for', 'several', 'other'),\n",
       " ('several', 'other', 'natural'),\n",
       " ('other', 'natural', 'language'),\n",
       " ('natural', 'language', 'processing'),\n",
       " ('language', 'processing', 'tasks'),\n",
       " ('processing', 'tasks', ','),\n",
       " ('tasks', ',', 'like'),\n",
       " (',', 'like', 'phrase'),\n",
       " ('like', 'phrase', 'chunking'),\n",
       " ('phrase', 'chunking', 'and'),\n",
       " ('chunking', 'and', 'named'),\n",
       " ('and', 'named', 'entity'),\n",
       " ('named', 'entity', 'recognition'),\n",
       " ('entity', 'recognition', '.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('In', 'this', 'paper', 'we', 'present', 'an'),\n",
       " ('this', 'paper', 'we', 'present', 'an', 'approach'),\n",
       " ('paper', 'we', 'present', 'an', 'approach', 'to'),\n",
       " ('we', 'present', 'an', 'approach', 'to', 'the'),\n",
       " ('present', 'an', 'approach', 'to', 'the', 'part-of-speech'),\n",
       " ('an', 'approach', 'to', 'the', 'part-of-speech', 'tagging'),\n",
       " ('approach', 'to', 'the', 'part-of-speech', 'tagging', 'problem'),\n",
       " ('to', 'the', 'part-of-speech', 'tagging', 'problem', 'based'),\n",
       " ('the', 'part-of-speech', 'tagging', 'problem', 'based', 'on'),\n",
       " ('part-of-speech', 'tagging', 'problem', 'based', 'on', 'particle'),\n",
       " ('tagging', 'problem', 'based', 'on', 'particle', 'swarm'),\n",
       " ('problem', 'based', 'on', 'particle', 'swarm', 'optimization'),\n",
       " ('based', 'on', 'particle', 'swarm', 'optimization', '.'),\n",
       " ('on', 'particle', 'swarm', 'optimization', '.', 'The'),\n",
       " ('particle', 'swarm', 'optimization', '.', 'The', 'part-of-speech'),\n",
       " ('swarm', 'optimization', '.', 'The', 'part-of-speech', 'tagging'),\n",
       " ('optimization', '.', 'The', 'part-of-speech', 'tagging', 'is'),\n",
       " ('.', 'The', 'part-of-speech', 'tagging', 'is', 'a'),\n",
       " ('The', 'part-of-speech', 'tagging', 'is', 'a', 'key'),\n",
       " ('part-of-speech', 'tagging', 'is', 'a', 'key', 'input'),\n",
       " ('tagging', 'is', 'a', 'key', 'input', 'feature'),\n",
       " ('is', 'a', 'key', 'input', 'feature', 'for'),\n",
       " ('a', 'key', 'input', 'feature', 'for', 'several'),\n",
       " ('key', 'input', 'feature', 'for', 'several', 'other'),\n",
       " ('input', 'feature', 'for', 'several', 'other', 'natural'),\n",
       " ('feature', 'for', 'several', 'other', 'natural', 'language'),\n",
       " ('for', 'several', 'other', 'natural', 'language', 'processing'),\n",
       " ('several', 'other', 'natural', 'language', 'processing', 'tasks'),\n",
       " ('other', 'natural', 'language', 'processing', 'tasks', ','),\n",
       " ('natural', 'language', 'processing', 'tasks', ',', 'like'),\n",
       " ('language', 'processing', 'tasks', ',', 'like', 'phrase'),\n",
       " ('processing', 'tasks', ',', 'like', 'phrase', 'chunking'),\n",
       " ('tasks', ',', 'like', 'phrase', 'chunking', 'and'),\n",
       " (',', 'like', 'phrase', 'chunking', 'and', 'named'),\n",
       " ('like', 'phrase', 'chunking', 'and', 'named', 'entity'),\n",
       " ('phrase', 'chunking', 'and', 'named', 'entity', 'recognition'),\n",
       " ('chunking', 'and', 'named', 'entity', 'recognition', '.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ngram\n",
    "# sentence_ngrams = list(nltk.ngrams(sentence_tokenize, N))\n",
    "sentence_ngrams = list(nltk.ngrams(sentence_tokenize, 6))\n",
    "sentence_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plan'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming - finding root word\n",
    "# Normalize words into its basic form\n",
    "# There are different types of stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "ps.stem(\"planning\")\n",
    "# Gives the basic form of word stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plan - stemmed: plan\n",
      "planned - stemmed: plan\n",
      "planning - stemmed: plan\n",
      "planner - stemmed: planner\n"
     ]
    }
   ],
   "source": [
    "words_stem = [\"plan\",\"planned\",\"planning\",\"planner\"]\n",
    "for words in words_stem:\n",
    "    print(words+ \" - stemmed: \" + ps.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plan - stemmed: plan\n",
      "planned - stemmed: plan\n",
      "planning - stemmed: plan\n",
      "planner - stemmed: plan\n"
     ]
    }
   ],
   "source": [
    "# Different types of stemmer are available\n",
    "# PorterStemmer\n",
    "# SnowballStemmer\n",
    "# LancasterStemmer\n",
    "# RegexpStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "lst = LancasterStemmer()\n",
    "for words in words_stem:\n",
    "    print(words + \" - stemmed: \"+lst.stem(words))\n",
    "# We can see better output using Lancaster Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corpus'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization\n",
    "# Morphological analysis word\n",
    "# Output of lemmatization is a proper word\n",
    "# Requires a total dictionary\n",
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "word_lem = WordNetLemmatizer()\n",
    "word_lem.lemmatize('corpora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see how many stop words available in english\n",
    "# Stopwords - stop words are used to eliminate unimportant words\n",
    "len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Natural', 'JJ')]\n",
      "[('language', 'NN')]\n",
      "[('processing', 'NN')]\n",
      "[('(', '(')]\n",
      "[('NLP', 'NN')]\n",
      "[(')', ')')]\n",
      "[('refers', 'NNS')]\n",
      "[('to', 'TO')]\n",
      "[('the', 'DT')]\n",
      "[('branch', 'NN')]\n",
      "[('of', 'IN')]\n",
      "[('computer', 'NN')]\n",
      "[('science—and', 'NN')]\n",
      "[('more', 'RBR')]\n",
      "[('specifically', 'RB')]\n",
      "[(',', ',')]\n",
      "[('the', 'DT')]\n",
      "[('branch', 'NN')]\n",
      "[('of', 'IN')]\n",
      "[('artificial', 'JJ')]\n",
      "[('intelligence', 'NN')]\n",
      "[('or', 'CC')]\n",
      "[('AI—concerned', 'VBN')]\n",
      "[('with', 'IN')]\n",
      "[('giving', 'VBG')]\n",
      "[('computers', 'NNS')]\n",
      "[('the', 'DT')]\n",
      "[('ability', 'NN')]\n",
      "[('to', 'TO')]\n",
      "[('understand', 'NN')]\n",
      "[('text', 'NN')]\n",
      "[('and', 'CC')]\n",
      "[('spoken', 'NN')]\n",
      "[('words', 'NNS')]\n",
      "[('in', 'IN')]\n",
      "[('much', 'JJ')]\n",
      "[('the', 'DT')]\n",
      "[('same', 'JJ')]\n",
      "[('way', 'NN')]\n",
      "[('human', 'NN')]\n",
      "[('beings', 'NNS')]\n",
      "[('can', 'MD')]\n",
      "[('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# POS Tagging\n",
    "sentence1 = \"Natural language processing (NLP) refers to the branch of computer science—and more specifically, the branch of artificial intelligence or AI—concerned with giving computers the ability to understand text and spoken words in much the same way human beings can.\"\n",
    "# Tokenization first\n",
    "sentence1_tokenized = word_tokenize(sentence1)\n",
    "for token in sentence1_tokenized:\n",
    "    print(nltk.pos_tag([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Apple/NNP)\n",
      "  (ORGANIZATION Inc./NNP)\n",
      "  is/VBZ\n",
      "  an/DT\n",
      "  (GPE American/JJ)\n",
      "  multinational/NN\n",
      "  technology/NN\n",
      "  company/NN\n",
      "  headquartered/VBD\n",
      "  in/IN\n",
      "  (GPE Cupertino/NNP)\n",
      "  ,/,\n",
      "  (GPE California/NNP)\n",
      "  ,/,\n",
      "  (GPE United/NNP States/NNPS)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "# Named entity recognition\n",
    "from nltk import ne_chunk\n",
    "sentence2 = \"Apple Inc. is an American multinational technology company headquartered in Cupertino, California, United States.\"\n",
    "# Tokenize\n",
    "sentence2_tokenize = word_tokenize(sentence2)\n",
    "sentence2_Pos_tags = nltk.pos_tag(sentence2_tokenize)\n",
    "sentence2_NER = ne_chunk(sentence2_Pos_tags)\n",
    "print(sentence2_NER)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93db20e0929ae22c4c40489de27df96fc0b9c170f5ac92379becd8a55b55b974"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
